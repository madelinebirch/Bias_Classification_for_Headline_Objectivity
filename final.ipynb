{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9814071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d58d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading 'headlines.csv' into a Pandas DataFrame\n",
    "headlines = pd.read_csv('Data/headlines.csv')\n",
    "\n",
    "# Showing first 5 rows of the DataFrame\n",
    "headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3553296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns 'url', 'Unnamed: 0', and 'index'\n",
    "headlines = headlines.drop(columns=['url', 'Unnamed: 0', 'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00dfca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02f113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f332a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting value counts for bias feature\n",
    "headlines['bias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b598d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting bias distribution\n",
    "\n",
    "# Setting Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting histogram of 'bias'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(headlines['bias'], bins=20, kde=True, color='blue')\n",
    "\n",
    "# Styling the plot\n",
    "plt.title('Distribution of Bias Scores', fontsize=16)\n",
    "plt.xlabel('Bias Score', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Showing the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a4fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating feature 'sentiment_polarity'\n",
    "\n",
    "# Creating a sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Applying the sentiment analyzer to each headline and storing the compound score - this takes a while to run\n",
    "headlines['sentiment_polarity'] = headlines['headline_no_site'].apply(lambda x: sid.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6312d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines['sentiment_polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d418d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print min and max values for sentiment polarity\n",
    "print(headlines['sentiment_polarity'].min())\n",
    "print(headlines['sentiment_polarity'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting dist of sentiment polarity\n",
    "\n",
    "# Setting Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting histogram of 'sentiment_polarity'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(headlines['sentiment_polarity'], bins=20, kde=True, color='green')\n",
    "\n",
    "# Styling the plot\n",
    "plt.title('Distribution of Sentiment Polarity Scores', fontsize=16)\n",
    "plt.xlabel('Sentiment Polarity Score', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Showing the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eed810db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering 'Day of the Week' and 'Month' Features\n",
    "headlines['Day_of_Week'] = pd.to_datetime(headlines['time']).dt.day_name()\n",
    "headlines['Month'] = pd.to_datetime(headlines['time']).dt.month\n",
    "\n",
    "# Engineering 'Hour of Dat' feature\n",
    "headlines['Hour_of_Day'] = pd.to_datetime(headlines['time']).dt.hour\n",
    "\n",
    "# Converting 'time' column to datetime format\n",
    "headlines['time'] = pd.to_datetime(headlines['time'], errors='coerce')\n",
    "\n",
    "# Extracting the year and creating a new 'Publication Year' feature\n",
    "headlines['Publication_Year'] = headlines['time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec62644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping time column\n",
    "headlines = headlines.drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4c994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating word count feature\n",
    "headlines['Word_Count'] = headlines['headline_no_site'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Creating text length feature\n",
    "headlines['Text_Length'] = headlines['headline_no_site'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da58ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6b295e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines['site'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dd504a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "656e3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a threshold for news sites with at least 5000 headlines\n",
    "min_headlines_threshold = 5000\n",
    "top_sites = headlines['site'].value_counts()\n",
    "top_sites = top_sites[top_sites >= min_headlines_threshold].index\n",
    "\n",
    "# Creating a new dataframe with only the sites with at least 5000 headlines\n",
    "headlines_filtered = headlines[headlines['site'].isin(top_sites)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e17320",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153991e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top 10 sites with most headlines\n",
    "top_10_sites = headlines_filtered['site'].value_counts().nlargest(10)\n",
    "\n",
    "# Creating a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(top_10_sites, labels=top_10_sites.index, autopct='%1.1f%%', colors=sns.color_palette('viridis'), startangle=90)\n",
    "plt.title('Top 10 News Sources Distribution')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48898345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting distribution of countries\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='country', data=headlines_filtered, palette='viridis')\n",
    "plt.title('Distribution of Countries')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Number of Headlines')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea539c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(headlines_filtered['Word_Count'], bins=30, color='skyblue', kde=False)\n",
    "plt.title('Distribution of Word Count in Headlines')\n",
    "plt.xlabel('Word_Count')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d04d8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(headlines_filtered['Text_Length'], bins=30, color='skyblue', kde=False)\n",
    "plt.title('Distribution of Text Length in Headlines')\n",
    "plt.xlabel('Word_Count')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ff2b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_filtered['bias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb22ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting values to drop\n",
    "values_to_drop = [0.666667, 0.833333]\n",
    "\n",
    "# Use boolean indexing to drop rows with specified values in 'bias' column\n",
    "headlines_filtered = headlines_filtered[~headlines_filtered['bias'].isin(values_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97472c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    headlines_filtered['bias'].between(0.000000, 0.000000, inclusive='both'),\n",
    "    headlines_filtered['bias'].between(0.1, 0.2, inclusive='both'),\n",
    "    headlines_filtered['bias'].between(0.3, 0.5, inclusive='both'),\n",
    "]\n",
    "\n",
    "labels = ['No Bias', 'Low Bias', 'High Bias']\n",
    "\n",
    "headlines_filtered['bias_category'] = np.select(conditions, labels, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d60f001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_filtered['bias_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63befa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd4d8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping original bias column\n",
    "headlines_filtered = headlines_filtered.drop(columns=['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edd13780",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_filtered.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98a6762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting the distribution of bias_category by Publication_Year\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x=\"Publication_Year\", hue=\"bias_category\", data=headlines_filtered)\n",
    "plt.title('Distribution of Bias Category by Publication_Year')\n",
    "plt.xlabel('Publication Year')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c42c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot a swarm plot for Sentiment_Polarity vs. bias with a gradient color scheme\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = sns.scatterplot(x='sentiment_polarity', y='bias_category', data=headlines_filtered, hue='bias_category', palette='viridis', size=3)\n",
    "\n",
    "# Style the plot\n",
    "plt.title('Distribution of Sentiment Polarity for Different Bias Categories', fontsize=16)\n",
    "plt.xlabel('Sentiment Polarity', fontsize=12)\n",
    "plt.ylabel('Bias Category', fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Create a ScalarMappable for the colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis')\n",
    "sm.set_array([])  # Set an empty array\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43a8e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the categorical columns to one-hot encode\n",
    "categorical_columns = ['site', 'country', 'Day_of_Week', 'Month', 'Hour_of_Day', 'Publication_Year']\n",
    "\n",
    "# Create one-hot encoded columns with 1s and 0s\n",
    "one_hot_encoded = pd.get_dummies(headlines_filtered[categorical_columns], drop_first=True, dtype=int)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "headlines_filtered_encoded = pd.concat([headlines_filtered, one_hot_encoded], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "headlines_filtered_encoded.drop(categorical_columns, axis=1, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "headlines_filtered_encoded.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18ef6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'headlines_no_site' column to 'headlines'\n",
    "headlines_filtered_encoded.rename(columns={'headline_no_site': 'headlines'}, inplace=True)\n",
    "\n",
    "headlines_filtered_encoded['headlines'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbaed774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the headline text\n",
    "headlines_filtered_encoded['tokenized_text'] = headlines_filtered_encoded['headlines'].apply(word_tokenize)\n",
    "\n",
    "# Remove non-alphabetic characters, handle empty strings, and extra spaces\n",
    "headlines_filtered_encoded['cleaned_text'] = headlines_filtered_encoded['tokenized_text'].apply(lambda tokens: [re.sub(r'[^a-zA-Z0-9]', '', token).strip() for token in tokens if re.sub(r'[^a-zA-Z0-9]', '', token).strip()])\n",
    "\n",
    "# Convert to lowercase\n",
    "headlines_filtered_encoded['cleaned_text'] = headlines_filtered_encoded['cleaned_text'].apply(lambda tokens: [token.lower() for token in tokens])\n",
    "\n",
    "# Lemmatization - this takes a minute or two to run\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "headlines_filtered_encoded['lemmatized_text'] = headlines_filtered_encoded['cleaned_text'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd861a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_df = headlines_filtered_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'headlines' column from lemmatized_df\n",
    "lemmatized_df.drop('headlines', axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows of lemmatized_df after dropping the column\n",
    "lemmatized_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stop words from the lemmatized_text column\n",
    "lemmatized_df['lemmatized_text_no_stopwords'] = lemmatized_df['lemmatized_text'].apply(lambda tokens: [token for token in tokens if token not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34962541",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_df['lemmatized_text_no_stopwords'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_vectorize = lemmatized_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11857ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['tokenized_text', 'cleaned_text', 'lemmatized_text']\n",
    "\n",
    "# Drop the specified columns\n",
    "df_to_vectorize.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_vectorize.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8639ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a gensim model and assigning it to 'model'- this will take a while to run\n",
    "model = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834be3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing available models in gensim-data\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    \"\"\"\n",
    "    Generate an embedding for the given text by mapping the embeddings into a 300-dimensional space. \n",
    "    For out-of-vocabulary words, we use a zero-vector replacement. \n",
    "    Remove stop words from the text.\n",
    "    -----\n",
    "    Input: text (str): Text to be embedded.\n",
    "    -----\n",
    "    Output: embedding_vector (np.array): Averaged embedding vector in a 300-dimensional space.\n",
    "    \"\"\"\n",
    "    tokenized = text\n",
    "    \n",
    "    word_embeddings = [np.zeros(300)]\n",
    "    for word in tokenized:\n",
    "        if word in model:\n",
    "            vector = model[word]\n",
    "        else:\n",
    "            vector = np.zeros(300)\n",
    "            \n",
    "        word_embeddings.append(vector)\n",
    "    \n",
    "    text_embedding = np.stack(word_embeddings).mean(axis=0)\n",
    "    \n",
    "    return text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e780ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying function over the lemmatized text column and assigning the results to new columns\n",
    "df_to_vectorize['headline_vectors'] = df_to_vectorize['lemmatized_text_no_stopwords'].apply(lambda x: text2vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75563fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_vectorize['headline_vectors'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c45cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making copy of df_to_vectorize\n",
    "final_df = df_to_vectorize.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'lemmatized_text_no_stopwords' column\n",
    "final_df = final_df.drop('lemmatized_text_no_stopwords', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61469476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking headlines vectors \n",
    "final_df['headline_vectors'][9207]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41293ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d222960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring there are no NaN values \n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c391c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating class weights\n",
    "\n",
    "# Extract the unique classes and their counts from the 'bias_category' column in final_df\n",
    "classes, counts = np.unique(final_df['bias_category'], return_counts=True)\n",
    "\n",
    "# Calculate class weights for the 'bias_category' column in final_df\n",
    "total_samples = len(final_df['bias_category'])\n",
    "class_weights = total_samples / (len(classes) * counts)\n",
    "\n",
    "# Create a dictionary mapping class labels to their respective weights\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Print the class weights\n",
    "print('Class Weights:', class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be0867",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a784b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting X and y variables\n",
    "X = final_df.drop('bias_category', axis=1)\n",
    "y = final_df['bias_category']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring there are no NaN values in y_train\n",
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring there are no NaN values in y_test\n",
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886de201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X_train vectors to arrays\n",
    "X_train_array = np.array(X_train['headline_vectors'].tolist())\n",
    "\n",
    "# Converting X_test vectors to arrays\n",
    "X_test_array = np.array(X_test['headline_vectors'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce998229",
   "metadata": {},
   "source": [
    "## Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198cb5a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ae061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LogisticRegression with class weights\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42, class_weight=class_weight_dict)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_model.fit(X_train_array, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_lr = logreg_model.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b751691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e285531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e214a",
   "metadata": {},
   "source": [
    "finding best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d74652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get unique classes from y_test\n",
    "unique_classes = np.unique(y_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "logreg_cm = confusion_matrix(y_test, y_pred_lr, labels=unique_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(logreg_cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=unique_classes, yticklabels=unique_classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37840ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66590245",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45606962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an instance of RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_array, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf_model.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68740094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e7cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "rf_cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88721621",
   "metadata": {},
   "source": [
    "## Complex Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8732b",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8971b",
   "metadata": {},
   "source": [
    "#### Simple Architecture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming y_train is a pandas Series with string labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encoding y_test and y_train\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# One-hot encoding y_train_encoded and y_test_encoded\n",
    "y_train_one_hot = to_categorical(y_train_encoded)\n",
    "y_test_one_hot = to_categorical(y_test_encoded)\n",
    "\n",
    "# Assuming y_train_encoded is an array of class labels\n",
    "class_labels = np.unique(y_train_encoded)\n",
    "\n",
    "# Compute class weights for the neural network\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=y_train_encoded)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the neural network model\n",
    "snn_model = Sequential()\n",
    "snn_model.add(Dense(64, input_dim=X_train_array.shape[1], activation='relu'))\n",
    "snn_model.add(Dense(32, activation='relu'))\n",
    "snn_model.add(Dense(len(class_labels), activation='softmax'))\n",
    "\n",
    "# Compile the model with class weights\n",
    "snn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with class weights\n",
    "snn_model.fit(X_train_array, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.2, class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the mapping between original class labels and encoded numbers\n",
    "class_labels_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Class Labels Mapping:\", class_labels_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c99098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_one_hot = snn_model.predict(X_test_array)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred_one_hot, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_encoded, y_pred_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7c8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
